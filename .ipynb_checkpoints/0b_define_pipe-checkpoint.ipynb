{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c8732c-611a-454b-ab1d-9a7dff57577b",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58959942-f664-4d7f-922b-4822ebecf3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import gmtime, strftime, sleep\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat\n",
    ")\n",
    "\n",
    "from sagemaker import (\n",
    "    AutoML,\n",
    "    AutoMLInput,\n",
    "    # get_execution_role,\n",
    "    # MetricsSource,\n",
    "    # ModelMetrics,\n",
    "    # ModelPackage,\n",
    ")\n",
    "\n",
    "# from sagemaker.s3 import s3_path_join, S3Downloader, S3Uploader\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.processing import Processor, ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TransformStep, CacheConfig\n",
    "from sagemaker.workflow.automl_step import AutoMLStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo, ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.properties import PropertyFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0568c-3136-4b7a-aa9e-7ebffa33667e",
   "metadata": {},
   "source": [
    "# Define session variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f9e8f1-2a65-40fb-8e00-36f1946cb7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = sagemaker.session.Session()\n",
    "pipe_session= PipelineSession()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "account_id = session.account_id()\n",
    "\n",
    "pipeline_name = \"FileFormatExample\"\n",
    "model_package_group_name = 'ProcessorEstimator'\n",
    "\n",
    "preprocessor_script = \"processor_model.py\"\n",
    "transformer_script = 'transformers.py'\n",
    "\n",
    "image_name = 'fit-fraudml-sagemaker-collab-20230511151434-35-97f3a42'\n",
    "ecr_repo = f'{account_id}.dkr.ecr.{region}.amazonaws.com/frm-svcs:{image_name}'\n",
    "\n",
    "timestamp_suffix = strftime(\"%Y-%m-%d-%H-%M\", gmtime())\n",
    "prefix = 'experiment' + '_' + timestamp_suffix\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"business_use\", \"Value\": \"sample\"}\n",
    "   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634e555-d06f-49e6-b5ec-532eefd04a48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eedd5e01-1932-416b-80c4-359f58633675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_name = 'fit-fraudml-sagemaker-collab-20230420153235-31-b24c974'\n",
    "# ecr_repo = f'{account_id}.dkr.ecr.{region}.amazonaws.com/frm-svcs:{image_name}'\n",
    "\n",
    "sample_size_param = ParameterString(\n",
    "    name=\"SampleSize\",\n",
    "    default_value='10000')\n",
    "\n",
    "group_filter = ParameterString(\n",
    "    name='Group',\n",
    "    default_value='second')\n",
    "\n",
    "target_col = ParameterString(\n",
    "    name='Target',\n",
    "    default_value='target')\n",
    "\n",
    "train_size = ParameterString(\n",
    "    name='TrainSize',\n",
    "    default_value='0.8')\n",
    "\n",
    "file_format = ParameterString(\n",
    "    name='FileFormat',\n",
    "    default_value='csv')\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1)\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name='TrainingInstanceType',\n",
    "    default_value=\"ml.m5.xlarge\")\n",
    "\n",
    "framework_version = ParameterString(\n",
    "    name=\"FrameworkVersion\",\n",
    "    default_value=\"1.2-1\")\n",
    "\n",
    "max_automl_runtime = ParameterInteger(\n",
    "    name=\"MaxAutoMLRuntime\",\n",
    "    default_value=3600)  # max. AutoML training runtime: 1 hour\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='ModelApprovalStatus',\n",
    "    default_value='PendingManualApproval')\n",
    "\n",
    "model_registration_metric_threshold = ParameterFloat(\n",
    "    name=\"ModelRegistrationMetricThreshold\",\n",
    "    default_value=0.1)\n",
    "\n",
    "step_cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after='PT12H')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b4316-4670-441b-a892-87d166a8fd1b",
   "metadata": {},
   "source": [
    "## Create Sample Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d4757b-f76e-4ccc-8fb6-105d80eef4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument version of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "sklearn_feats_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    sagemaker_session=pipe_session,\n",
    "    base_job_name=\"sample-pipeline-job\"\n",
    ")\n",
    "\n",
    "step_create_feats = ProcessingStep(\n",
    "    name=\"create_feats\",\n",
    "    processor=sklearn_feats_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"features\",\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'sample_data'\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments = [\"--sample-size\", sample_size_param, '--group', group_filter],\n",
    "    code=\"create_feats.py\",\n",
    "    cache_config=step_cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b329264-7064-4a6a-8945-ac282e9e14de",
   "metadata": {},
   "source": [
    "## Create Sample Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b771c8c-061d-4fcc-8eb5-9072d0d70df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument version of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "sklearn_gt_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    sagemaker_session=pipe_session,\n",
    "    base_job_name=\"sample-pipeline-job\"\n",
    ")\n",
    "\n",
    "step_create_gt = ProcessingStep(\n",
    "    name=\"create_gt\",\n",
    "    processor=sklearn_gt_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"ground_truth\",\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'sample_data'\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments = [\"--sample-size\", sample_size_param, '--target', target_col],\n",
    "    code=\"create_gt.py\",\n",
    "    cache_config=step_cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edae66-487f-4af2-849b-9f7814d8e9e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split Data, Train Preprocessor, Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369c5a12-0696-476f-8804-d9d1e604b3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=ecr_repo,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count)\n",
    "\n",
    "step_create_preprocessor = ProcessingStep(\n",
    "    name=\"create_preprocessor\",\n",
    "    processor=pre_processor,\n",
    "    code='processor_script.py',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_create_feats.properties.ProcessingOutputConfig.Outputs['features'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/data/feats'),\n",
    "        ProcessingInput(\n",
    "            source=step_create_gt.properties.ProcessingOutputConfig.Outputs['ground_truth'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/data/gt')],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"encoder\",\n",
    "            source=\"/opt/ml/processing/output/encoder\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'encoder'])),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"encoder_cols\",\n",
    "            source=\"/opt/ml/processing/output/encoder_cols\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'encoder_cols'])),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'train'])),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validate\",\n",
    "            source=\"/opt/ml/processing/output/validate\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'validate'])),\n",
    "        # ProcessingOutput(\n",
    "        #     output_name=\"test\",\n",
    "        #     source=\"/opt/ml/processing/output/test\",\n",
    "        #     destination=Join(\n",
    "        #         on=\"/\",\n",
    "        #         values=[\n",
    "        #             \"s3://{}\".format(bucket),\n",
    "        #             prefix,\n",
    "        #             'test'\n",
    "        #         ],\n",
    "        #     ),\n",
    "        # ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_x\",\n",
    "            source=\"/opt/ml/processing/output/test/feats\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'test',\n",
    "                    'feats'])),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_y\",\n",
    "            source=\"/opt/ml/processing/output/test/target\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'test',\n",
    "                    'target']))],\n",
    "    job_arguments = [\n",
    "        '--target', target_col,\n",
    "        \"--train-size\", train_size,\n",
    "        '--file-format', file_format],\n",
    "    cache_config=step_cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56f2481-accb-4a87-9f45-6a7039be5b2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c25539-27ff-4c88-8e2e-27f566e761cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "The input argument version of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py:445: UserWarning: Profiling is enabled on the provided estimator. The default profiler rule includes a timestamp which will change each time the pipeline is upserted, causing cache misses. If profiling is not needed, set disable_profiler to True on the estimator.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "processor_model = SKLearn(\n",
    "    entry_point='processor_model.py',\n",
    "    role=role,\n",
    "    instance_type=training_instance_type,\n",
    "    framework_version=framework_version,\n",
    "    sagemaker_session=pipe_session,\n",
    "    dependencies=[transformer_script])\n",
    "\n",
    "step_train_preprocessor_model = TrainingStep(\n",
    "    name=\"PreprocessModel\",\n",
    "    estimator=processor_model,\n",
    "    inputs={\n",
    "        'input_model':TrainingInput(\n",
    "            s3_data=step_create_preprocessor.properties.ProcessingOutputConfig.Outputs['encoder'].S3Output.S3Uri,\n",
    "            content_type='text/csv')},\n",
    "    cache_config=step_cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab7654-b66e-4bf1-8ede-a4ac4f81aa7d",
   "metadata": {},
   "source": [
    "## Train AutoML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b54168-1694-48c1-abf3-38ce0785d36c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py:273: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML(\n",
    "    role=role,\n",
    "    target_attribute_name=target_col,\n",
    "    # problem_type='BinaryClassification',\n",
    "    # job_objective={'auc':?}, # the objective metric used to measure the predictive quality of an AutoML job. In the format of: {“MetricName”: str}\n",
    "    sagemaker_session=pipe_session,\n",
    "    # max_candidates=10, #maximum number of times a training job is allowed to run\n",
    "    # max_runtime_per_training_job_in_seconds=max_automl_runtime, # maximum time, in seconds, that each training job executed inside hyperparameter tuning is allowed to run as part of a hyperparameter tuning job\n",
    "    total_job_runtime_in_seconds=max_automl_runtime, # the total wait time of an AutoML job\n",
    "    # feature_specification_s3_uri=?, # a URL to the Amazon S3 data source containing selected features and specified data types from the input data source of an AutoML job.\n",
    "    mode=\"ENSEMBLING\",  # only ensembling mode is supported for native AutoML step integration in SageMaker Pipelines\n",
    ")\n",
    "\n",
    "train_args = automl.fit(\n",
    "    inputs=[\n",
    "        AutoMLInput(\n",
    "            inputs=step_create_preprocessor.properties.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri,\n",
    "            target_attribute_name=target_col,\n",
    "            channel_type=\"training\"\n",
    "        ),\n",
    "        AutoMLInput(\n",
    "            inputs=step_create_preprocessor.properties.ProcessingOutputConfig.Outputs['validate'].S3Output.S3Uri,\n",
    "            target_attribute_name=target_col,\n",
    "            channel_type=\"validation\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "step_auto_ml_training = AutoMLStep(\n",
    "    name=\"AutoMLTrainingStep\",\n",
    "    step_args=train_args,\n",
    "    cache_config=step_cache_config\n",
    ")\n",
    "\n",
    "best_auto_ml_model = step_auto_ml_training.get_best_auto_ml_model(\n",
    "    role,\n",
    "    sagemaker_session=pipe_session)\n",
    "\n",
    "step_args_create_model = best_auto_ml_model.create(instance_type=processing_instance_type)\n",
    "step_create_AutoMLmodel = ModelStep(name=\"ModelCreationStep\", step_args=step_args_create_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d3b88-7e51-4945-958e-c17cfd8c55c2",
   "metadata": {},
   "source": [
    "## Batch Transform Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2db88842-af1b-45d5-8ec4-2af7f0f64b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    model_name=step_create_AutoMLmodel.properties.ModelName,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    output_path=Join(on=\"/\", values=[\"s3:/\", bucket, prefix, \"transform\"]),\n",
    "    strategy='MultiRecord',\n",
    "    assemble_with='Line',\n",
    "    accept = 'text/csv',\n",
    "    # max_payload=100,\n",
    "    sagemaker_session=pipe_session,\n",
    ")\n",
    "step_batch_transform = TransformStep(\n",
    "    name=\"BatchTransformStep\",\n",
    "    step_args=transformer.transform(\n",
    "        data=step_create_preprocessor.properties.ProcessingOutputConfig.Outputs['test_x'].S3Output.S3Uri,\n",
    "        content_type=\"text/csv\",\n",
    "        split_type='Line'),\n",
    "    cache_config=step_cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05474511-c5e1-4b13-a4f6-934415cba2f4",
   "metadata": {},
   "source": [
    "## Evaluate AutoML Model\n",
    "\n",
    "Need to update this code. Specifically, need to know the output of the transform_step so that you can reference it in the eval script. Will also need to update the eval script, as the predictions are already complete using this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f370f643-9a7e-4e3d-b8b0-68b4efac431b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument version of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "eval_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ae7923-3ebe-4a51-9ed7-0ce2754361dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation\",\n",
    "    output_name=\"evaluation_metrics\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_evaluation = ProcessingStep(\n",
    "    name=\"ModelEvaluationStep\",\n",
    "    processor=eval_processor,\n",
    "    code=\"evaluate.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_batch_transform.properties.TransformOutput.S3OutputPath,\n",
    "            destination=\"/opt/ml/processing/input/predictions\"),\n",
    "        ProcessingInput(\n",
    "            source=step_create_preprocessor.properties.ProcessingOutputConfig.Outputs['test_y'].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input/true_labels\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation_metrics\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(on=\"/\", values=[\"s3:/\", bucket, prefix, \"evaluation\"]))],\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=step_cache_config)\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on='/',\n",
    "            values=[\n",
    "                step_evaluation.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0]['S3Output']['S3Uri'],\n",
    "                'evaluation.json']),\n",
    "        content_type='application/json'),\n",
    "    explainability=MetricsSource(\n",
    "        s3_uri=step_auto_ml_training.properties.BestCandidateProperties.ExplainabilityJsonReportPath,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b126086-ec50-40e3-84e8-4746f46513ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_metrics = ModelMetrics(\n",
    "#     model_statistics=MetricsSource(\n",
    "#         s3_uri=step_auto_ml_training.properties.BestCandidateProperties.ModelInsightsJsonReportPath,\n",
    "#         content_type=\"application/json\",\n",
    "#     ),\n",
    "#     explainability=MetricsSource(\n",
    "#         s3_uri=step_auto_ml_training.properties.BestCandidateProperties.ExplainabilityJsonReportPath,\n",
    "#         content_type=\"application/json\",\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a67cea-b16c-43c2-a1e0-c5d891e63583",
   "metadata": {},
   "source": [
    "## Create Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e391c82c-ffd2-4a9a-8d91-293029f85803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_model = SKLearnModel(\n",
    "    name='PreprocessModel',\n",
    "    model_data=step_train_preprocessor_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    role=role,\n",
    "    sagemaker_session=pipe_session,\n",
    "    entry_point=preprocessor_script,\n",
    "    dependencies=[transformer_script],\n",
    "    framework_version=framework_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80e192cc-ba90-4c9a-a7ce-79e6d38c95a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"inference-pipeline-\" + timestamp_suffix\n",
    "endpoint_name = \"inference-pipeline-ep-\" + timestamp_suffix\n",
    "\n",
    "\n",
    "pipe_model = PipelineModel(\n",
    "    models=[preprocess_model, best_auto_ml_model],\n",
    "    role=role,\n",
    "    sagemaker_session=pipe_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfb201-6223-4dcc-b878-668638dac4d1",
   "metadata": {},
   "source": [
    "## Registration Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdcbce03-dbdd-494c-a1cf-135f429d7e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument version of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "step_register_model = RegisterModel(\n",
    "    name=model_name,\n",
    "    model=pipe_model,\n",
    "    content_types=[\"text/csv\", \"text/csv\"],\n",
    "    response_types=[\"text/csv\", \"text/csv\"],\n",
    "    inference_instances=[processing_instance_type, processing_instance_type],\n",
    "    transform_instances=[processing_instance_type, processing_instance_type],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics)\n",
    "\n",
    "# # step_register_model = ModelStep(\n",
    "# #     name=\"ModelRegistrationStep\",\n",
    "# #     step_args=step_args_register_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecee0150-6a1c-4577-8f1d-80bf49d4c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_conditional_registration = ConditionStep(\n",
    "    name=\"ConditionalRegistrationStep\",\n",
    "    conditions=[\n",
    "        ConditionGreaterThanOrEqualTo(\n",
    "            left=JsonGet(\n",
    "                step_name=step_evaluation.name,\n",
    "                property_file=evaluation_report,\n",
    "                json_path=\"binary_classification_metrics.accuracy.value\",\n",
    "            ),\n",
    "            right=model_registration_metric_threshold,\n",
    "        )\n",
    "    ],\n",
    "    if_steps=[step_register_model],\n",
    "    else_steps=[],  # pipeline end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1351fe-24b4-4d72-a44d-8a3bf24ccf0a",
   "metadata": {},
   "source": [
    "## Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8478ca31-2d48-48c2-9446-7b4b9829fde3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        sample_size_param,\n",
    "        group_filter,\n",
    "        target_col,\n",
    "        train_size,\n",
    "        file_format,\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        framework_version,\n",
    "        max_automl_runtime,\n",
    "        model_approval_status,\n",
    "        model_registration_metric_threshold,\n",
    "        step_cache_config\n",
    "    ],\n",
    "    steps=[\n",
    "        step_create_feats,\n",
    "        step_create_gt,\n",
    "        step_create_preprocessor,\n",
    "        step_train_preprocessor_model,\n",
    "        step_auto_ml_training,\n",
    "        step_create_AutoMLmodel,\n",
    "        step_batch_transform,\n",
    "        step_evaluation,\n",
    "        # step_register_model,\n",
    "        step_conditional_registration\n",
    "    ],\n",
    "    sagemaker_session=pipe_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a604f67c-2d76-48e7-894e-6829e821baac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:707031497630:pipeline/fileformatexample/execution/w4odyhnuechc', sagemaker_session=<sagemaker.workflow.pipeline_context.PipelineSession object at 0x7fb172bbc350>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(\n",
    "    execution_display_name=\"SamplePipe-10MBaseline\",\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType='ml.m5.2xlarge',\n",
    "        TrainingInstanceType='ml.m5.2xlarge',\n",
    "        MaxAutoMLRuntime=3600,\n",
    "        SampleSize='10000000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55265474-076e-4cc6-99ef-12d161442ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
