{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SM11: Train, Evaluate, Register Prebuilt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:707031497630:pipeline/insexample/execution/dztwn1somy3t', sagemaker_session=<sagemaker.session.Session object at 0x7f28e8362730>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance-Co-Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "train_uri = f's3://{bucket}/{prefix}/final/train/train_feats.csv'\n",
    "validate_uri = f's3://{bucket}/{prefix}/final/validate/validate_feats.csv'\n",
    "test_uri = f's3://{bucket}/{prefix}/final/test/test_feats.csv'\n",
    "\n",
    "\n",
    "# tags = [\n",
    "#     {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "#     {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "#    ]\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "    \n",
    "train_data = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=train_uri\n",
    ")\n",
    "validate_data = ParameterString(\n",
    "    name=\"ValidateData\",\n",
    "    default_value=validate_uri\n",
    ")\n",
    "test_data = ParameterString(\n",
    "    name=\"TestData\",\n",
    "    default_value=test_uri\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='ModelApprovalStatus',\n",
    "    default_value='PendingManualApproval'\n",
    ")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.2-2',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge')\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    disable_profiler=True,\n",
    "    output_path=Join(\n",
    "        on=\"/\",\n",
    "        values=[\n",
    "            \"s3://{}\".format(bucket),\n",
    "            prefix,\n",
    "            ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "            \"model\"],\n",
    "            ))\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    num_round=25)\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name='train_model',\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        'train':TrainingInput(\n",
    "            s3_data=train_data,\n",
    "            content_type='text/csv'),\n",
    "        'validation':TrainingInput(\n",
    "            s3_data=validate_data,\n",
    "            content_type='text/csv')\n",
    "            })\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    role=role,\n",
    "    base_job_name=\"ins-example-job\")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json')\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='evaluate_model',\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=test_data,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/evaluation',\n",
    "            destination=Join(\n",
    "                on='/',\n",
    "                values=[\n",
    "                    's3://{}'.format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    'evaluation-report']\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code='evaluate.py',\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on='/',\n",
    "            values=[\n",
    "                step_evaluate.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0]['S3Output']['S3Uri'],\n",
    "                'evaluation.json']\n",
    "        ),\n",
    "        content_type='application/json')\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name='register-model',\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge', 'ml.m5.large'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        train_data,\n",
    "        validate_data,\n",
    "        test_data,\n",
    "        model_approval_status\n",
    "    ],\n",
    "    steps=[step_train, step_evaluate, step_register])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(execution_display_name=\"InsPrebuiltModelEval-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
