{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa68c1c4-bd15-4c82-9691-279ee83f93e1",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69168c00-2057-4be3-9396-dc1c1462b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL pipe\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString)\n",
    "\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance Co Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "\n",
    "input_uri = Join(on=\"/\", values=['s3://{}'.format(bucket),\n",
    "                                      prefix,\n",
    "                                      'raw'])\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "    {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "   ]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"ins-example-job\"\n",
    ")\n",
    "\n",
    "step_etl = ProcessingStep(\n",
    "    name=\"etl\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_uri, destination=\"/opt/ml/processing/input\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"clean\",\n",
    "            source=\"/opt/ml/processing/output\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'clean'\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code=\"etl.py\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count\n",
    "    ],\n",
    "    steps=[step_etl])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(\n",
    "    execution_display_name=\"InsClean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539b164-6323-4050-8464-f8736ae5c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess pipe\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance Co Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "input_uri = f's3://{bucket}/{prefix}/clean/full_data.csv'\n",
    "\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "    {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "   ]\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "    \n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_uri\n",
    ")\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"ins-example-job\"\n",
    ")\n",
    "\n",
    "step_preprocess = ProcessingStep(\n",
    "    name=\"preprocess_data\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'final',\n",
    "                    \"train\"\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validate\",\n",
    "            source=\"/opt/ml/processing/output/validate\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'final',\n",
    "                    \"validate\"\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'final',\n",
    "                    \"test\"\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"encoder\",\n",
    "            source=\"/opt/ml/processing/output/encoder\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    'final',\n",
    "                    'encoder'\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"preprocess.py\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_preprocess])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(execution_display_name=\"InsPreprocess10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33062109-e7ab-46be-b35c-820af8505f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Prebuilt model\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance Co Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "train_uri = f's3://{bucket}/{prefix}/final/train/train_feats.csv'\n",
    "validate_uri = f's3://{bucket}/{prefix}/final/validate/validate_feats.csv'\n",
    "\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "    {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "   ]\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "    \n",
    "train_data = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=train_uri\n",
    ")\n",
    "validate_data = ParameterString(\n",
    "    name=\"ValidateData\",\n",
    "    default_value=validate_uri\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='ModelApprovalStatus', default_value='PendingManualApproval')\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.2-2',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge')\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    disable_profiler=True)\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    num_round=25)\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name='train_model',\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        'train':TrainingInput(\n",
    "            s3_data=train_data,\n",
    "            content_type='text/csv'),\n",
    "        'validation':TrainingInput(\n",
    "            s3_data=validate_data,\n",
    "            content_type='text/csv')\n",
    "            })\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        train_data,\n",
    "        validate_data\n",
    "    ],\n",
    "    steps=[step_train])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(execution_display_name=\"InsPrebuiltModel3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1a2dd-6039-4fe4-9979-261ab39470aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and evaluate\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance-Co-Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "train_uri = f's3://{bucket}/{prefix}/final/train/train_feats.csv'\n",
    "validate_uri = f's3://{bucket}/{prefix}/final/validate/validate_feats.csv'\n",
    "test_uri = f's3://{bucket}/{prefix}/final/test/test_feats.csv'\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "    {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "   ]\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "    \n",
    "train_data = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=train_uri\n",
    ")\n",
    "validate_data = ParameterString(\n",
    "    name=\"ValidateData\",\n",
    "    default_value=validate_uri\n",
    ")\n",
    "test_data = ParameterString(\n",
    "    name=\"TestData\",\n",
    "    default_value=test_uri\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='ModelApprovalStatus',\n",
    "    default_value='PendingManualApproval'\n",
    ")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.2-2',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge')\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    disable_profiler=True,\n",
    "    output_path=Join(\n",
    "        on=\"/\",\n",
    "        values=[\n",
    "            \"s3://{}\".format(bucket),\n",
    "            prefix,\n",
    "            ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "            \"model\"],\n",
    "            ))\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    num_round=25)\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name='train_model',\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        'train':TrainingInput(\n",
    "            s3_data=train_data,\n",
    "            content_type='text/csv'),\n",
    "        'validation':TrainingInput(\n",
    "            s3_data=validate_data,\n",
    "            content_type='text/csv')\n",
    "            })\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    role=role,\n",
    "    base_job_name=\"ins-example-job\")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json')\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='evaluate_model',\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=test_data,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/evaluation',\n",
    "            destination=Join(\n",
    "                on='/',\n",
    "                values=[\n",
    "                    's3://{}'.format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    'evaluation-report']\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code='evaluate_extd.py',\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on='/',\n",
    "            values=[\n",
    "                step_evaluate.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0]['S3Output']['S3Uri'],\n",
    "                'evaluation.json']\n",
    "        ),\n",
    "        content_type='application/json')\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name='register-model',\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge', 'ml.m5.large'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        train_data,\n",
    "        validate_data,\n",
    "        test_data,\n",
    "        model_approval_status\n",
    "    ],\n",
    "    steps=[step_train, step_evaluate, step_register])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(execution_display_name=\"InsPrebuiltModelEvalExtd-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea81a87-24a0-4f07-a30f-0e77741aa5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, evaluate, and hyperparameter tune\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance-Co-Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "train_uri = f's3://{bucket}/{prefix}/final/train/train_feats.csv'\n",
    "validate_uri = f's3://{bucket}/{prefix}/final/validate/validate_feats.csv'\n",
    "test_uri = f's3://{bucket}/{prefix}/final/test/test_feats.csv'\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "    {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "   ]\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "\n",
    "max_training_jobs = ParameterInteger(name='MaximumTrainingJobs', default_value=1)\n",
    "max_parallel_training_jobs = ParameterInteger('MaxParallelTrainingJobs', default_value=1)\n",
    "    \n",
    "train_data = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=train_uri\n",
    ")\n",
    "validate_data = ParameterString(\n",
    "    name=\"ValidateData\",\n",
    "    default_value=validate_uri\n",
    ")\n",
    "test_data = ParameterString(\n",
    "    name=\"TestData\",\n",
    "    default_value=test_uri\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='ModelApprovalStatus',\n",
    "    default_value='PendingManualApproval'\n",
    ")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.2-2',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge')\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    disable_profiler=True,\n",
    "#     output_path=Join(\n",
    "#         on=\"/\",\n",
    "#         values=[\n",
    "#             \"s3://{}\".format(bucket),\n",
    "#             prefix,\n",
    "#             ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "#             \"model\"])\n",
    ")\n",
    "\n",
    "# xgb_estimator.set_hyperparameters(\n",
    "#     max_depth=5,\n",
    "#     eta=0.2,\n",
    "#     gamma=4,\n",
    "#     min_child_weight=6,\n",
    "#     subsample=0.8,\n",
    "#     objective='binary:logistic',\n",
    "#     num_round=25)\n",
    "\n",
    "xgb_tuner = HyperparameterTuner(\n",
    "    estimator=xgb_estimator,\n",
    "    objective_metric_name=\"validation:f1\",\n",
    "    hyperparameter_ranges={\n",
    "        'max_depth': IntegerParameter(1, 10),\n",
    "        'eta': ContinuousParameter(0, 0.5),\n",
    "        'gamma': ContinuousParameter(0, 5),\n",
    "        'min_child_weight': ContinuousParameter(1, 120),\n",
    "        'num_round': IntegerParameter(1, 2000)\n",
    "    },\n",
    "    max_jobs=max_training_jobs,\n",
    "    max_parallel_jobs=max_parallel_training_jobs)\n",
    "\n",
    "# xgb_tuner = HyperparameterTuner(\n",
    "#     estimator=xgb_estimator,\n",
    "#     objective_metric_name=\"validation:auc\",\n",
    "#     hyperparameter_ranges={\n",
    "#         'eta': ContinuousParameter(0, 0.5),\n",
    "#         'alpha': ContinuousParameter(0, 1000),\n",
    "#         'min_child_weight': ContinuousParameter(1, 120),\n",
    "#         'max_depth': IntegerParameter(1, 10),\n",
    "#         'num_round': IntegerParameter(1, 2000),\n",
    "#         'subsample': ContinuousParameter(0.5, 1)\n",
    "#     },\n",
    "#     max_jobs=max_training_jobs,\n",
    "#     max_parallel_jobs=max_parallel_training_jobs)\n",
    "\n",
    "# step_train = TrainingStep(\n",
    "#     name='train_model',\n",
    "# #     estimator=xgb_estimator,\n",
    "#     inputs={\n",
    "#         'train':TrainingInput(\n",
    "#             s3_data=train_data,\n",
    "#             content_type='text/csv'),\n",
    "#         'validation':TrainingInput(\n",
    "#             s3_data=validate_data,\n",
    "#             content_type='text/csv')\n",
    "#             })\n",
    "\n",
    "step_tune = TuningStep(\n",
    "    name='train-tune-model',\n",
    "    tuner=xgb_tuner,\n",
    "    inputs={\n",
    "        'train':TrainingInput(\n",
    "            s3_data=train_data,\n",
    "            content_type='text/csv'),\n",
    "        'validation':TrainingInput(\n",
    "            s3_data=validate_data,\n",
    "            content_type='text/csv')})\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    role=role,\n",
    "    base_job_name=\"ins-example-job\")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json')\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='evaluate_model',\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tune.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=test_data,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/evaluation',\n",
    "            destination=Join(\n",
    "                on='/',\n",
    "                values=[\n",
    "                    's3://{}'.format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    'evaluation-report']\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code='evaluate_extd.py',\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on='/',\n",
    "            values=[\n",
    "                step_evaluate.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0]['S3Output']['S3Uri'],\n",
    "                'evaluation.json']\n",
    "        ),\n",
    "        content_type='application/json')\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name='register-model',\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=step_tune.get_top_model_s3_uri(top_k=0, s3_bucket=bucket),\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge', 'ml.m5.large'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        max_training_jobs,\n",
    "        max_parallel_training_jobs,\n",
    "        train_data,\n",
    "        validate_data,\n",
    "        test_data,\n",
    "        model_approval_status\n",
    "    ],\n",
    "    steps=[\n",
    "#         step_train,\n",
    "        step_tune,\n",
    "        step_evaluate,\n",
    "        step_register])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(execution_display_name=\"InsPrebuiltModelTune-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5cfb83-8193-40ba-9feb-11c69655676e",
   "metadata": {},
   "source": [
    "# Train, Evaluate, Register Prebuilt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29574af-3d39-4d46-84bd-5d755e9f0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()\n",
    "prefix = '1_ins_dataset'\n",
    "\n",
    "pipeline_name = \"InsExample\"  # SageMaker Pipeline name\n",
    "model_package_group_name = \"Insurance-Co-Example\"  # Model name in model registry\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "train_uri = f's3://{bucket}/{prefix}/final/train/train_feats.csv'\n",
    "validate_uri = f's3://{bucket}/{prefix}/final/validate/validate_feats.csv'\n",
    "test_uri = f's3://{bucket}/{prefix}/final/test/test_feats.csv'\n",
    "\n",
    "tags = [\n",
    "    {\"Key\": \"DATASET\", \"Value\": \"InsCOIL\"},\n",
    "    {\"Key\": \"SOURCE\", \"Value\": \"UCI\"}\n",
    "   ]\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.medium\")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "    \n",
    "train_data = ParameterString(\n",
    "    name=\"TrainData\",\n",
    "    default_value=train_uri\n",
    ")\n",
    "validate_data = ParameterString(\n",
    "    name=\"ValidateData\",\n",
    "    default_value=validate_uri\n",
    ")\n",
    "test_data = ParameterString(\n",
    "    name=\"TestData\",\n",
    "    default_value=test_uri\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name='ModelApprovalStatus',\n",
    "    default_value='PendingManualApproval'\n",
    ")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.2-2',\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge')\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    disable_profiler=True,\n",
    "    output_path=Join(\n",
    "        on=\"/\",\n",
    "        values=[\n",
    "            \"s3://{}\".format(bucket),\n",
    "            prefix,\n",
    "            ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "            \"model\"],\n",
    "            ))\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective='binary:logistic',\n",
    "    num_round=25)\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name='train_model',\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "        'train':TrainingInput(\n",
    "            s3_data=train_data,\n",
    "            content_type='text/csv'),\n",
    "        'validation':TrainingInput(\n",
    "            s3_data=validate_data,\n",
    "            content_type='text/csv')\n",
    "            })\n",
    "\n",
    "evaluate_model_processor = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    role=role,\n",
    "    base_job_name=\"ins-example-job\")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json')\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name='evaluate_model',\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=test_data,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/evaluation',\n",
    "            destination=Join(\n",
    "                on='/',\n",
    "                values=[\n",
    "                    's3://{}'.format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    'evaluation-report']\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    code='evaluate.py',\n",
    "    property_files=[evaluation_report]\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on='/',\n",
    "            values=[\n",
    "                step_evaluate.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0]['S3Output']['S3Uri'],\n",
    "                'evaluation.json']\n",
    "        ),\n",
    "        content_type='application/json')\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name='register-model',\n",
    "    estimator=xgb_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['text/csv'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge', 'ml.m5.large'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        train_data,\n",
    "        validate_data,\n",
    "        test_data,\n",
    "        model_approval_status\n",
    "    ],\n",
    "    steps=[step_train, step_evaluate, step_register])\n",
    "\n",
    "pipeline.upsert(role_arn=role, tags=tags)\n",
    "\n",
    "pipeline.start(execution_display_name=\"InsPrebuiltModelEval-7\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
